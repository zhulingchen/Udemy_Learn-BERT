{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ca6rYUxNi_MO"
   },
   "source": [
    "# Stage 1: Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76HfPILdC5lD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.1.0\n",
      "TensorFlow Hub Version: 0.8.0\n",
      "bert-for-tf2 Version: 0.14.4\n",
      "Query free memories from all GPUs: nvidia-smi --query-gpu=memory.free --format=csv,noheader,nounits\n",
      "Free memory list (MB): [10979, 10091, 11168, 10522]\n",
      "Query names of processes running on the GPU index 0: nvidia-smi --query-compute-apps=process_name --format=csv,noheader,nounits --id=0\n",
      "Names of processes running on the GPU index 0: []\n",
      "Query names of processes running on the GPU index 1: nvidia-smi --query-compute-apps=process_name --format=csv,noheader,nounits --id=1\n",
      "Names of processes running on the GPU index 1: ['/usr/bin/python3']\n",
      "Query names of processes running on the GPU index 2: nvidia-smi --query-compute-apps=process_name --format=csv,noheader,nounits --id=2\n",
      "Names of processes running on the GPU index 2: []\n",
      "Query names of processes running on the GPU index 3: nvidia-smi --query-compute-apps=process_name --format=csv,noheader,nounits --id=3\n",
      "Names of processes running on the GPU index 3: ['/usr/bin/python3']\n",
      "Left next 1 GPU(s) unmasked: [2] (from [2 0] available)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "\n",
    "import bert\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"TensorFlow Hub Version:\", hub.__version__)\n",
    "print(\"bert-for-tf2 Version:\", bert.__version__)\n",
    "\n",
    "from utility import mask_busy_gpus\n",
    "mask_busy_gpus(1)  # randomly select 1 unused GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f0_xu0I3jFP9"
   },
   "source": [
    "# Stage 2: Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v60JTFKojIq5"
   },
   "source": [
    "## Loading files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mTtO7NkPjKUd"
   },
   "source": [
    "We import files from our personal Google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f6iT5nxDHLRz"
   },
   "outputs": [],
   "source": [
    "cols = [\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n",
    "data = pd.read_csv(\"./data/train.csv\",\n",
    "                   header=None,\n",
    "                   names=cols,\n",
    "                   engine=\"python\",\n",
    "                   encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kKnCVewUIBkc"
   },
   "outputs": [],
   "source": [
    "data.drop([\"id\", \"date\", \"query\", \"user\"],\n",
    "          axis=1,\n",
    "          inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Quzx5tnjUtl"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M8hlexmRjXIS"
   },
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jBSUDL-UP-W_"
   },
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    tweet = BeautifulSoup(tweet, \"lxml\").get_text()\n",
    "    # Removing the @\n",
    "    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\n",
    "    # Removing the URL links\n",
    "    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\n",
    "    # Keeping only letters\n",
    "    tweet = re.sub(r\"[^a-zA-Z.!?']\", ' ', tweet)\n",
    "    # Removing additional whitespaces\n",
    "    tweet = re.sub(r\" +\", ' ', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8jiMaQsLWiTS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned tweet #0:  Awww that's a bummer. You shoulda got David Carr of Third Day to do it. D\n",
      "Cleaned tweet #1: is upset that he can't update his Facebook by texting it... and might cry as a result School today also. Blah!\n",
      "Cleaned tweet #2:  I dived many times for the ball. Managed to save The rest go out of bounds\n",
      "Cleaned tweet #3: my whole body feels itchy and like its on fire \n",
      "Cleaned tweet #4:  no it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. \n",
      "Cleaned tweet #5:  not the whole crew \n",
      "Cleaned tweet #6: Need a hug \n",
      "Cleaned tweet #7:  hey long time no see! Yes.. Rains a bit only a bit LOL I'm fine thanks how's you ?\n",
      "Cleaned tweet #8:  K nope they didn't have it \n",
      "Cleaned tweet #9:  que me muera ? \n"
     ]
    }
   ],
   "source": [
    "data_clean = [clean_tweet(tweet) for tweet in data.text]\n",
    "\n",
    "# print first 10 cleaned tweets\n",
    "for i, tw in enumerate(data_clean[:10]):\n",
    "    print(\"Cleaned tweet #%d: %s\" % (i, tw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EaqLE0fdWtni"
   },
   "outputs": [],
   "source": [
    "data_labels = data.sentiment.values\n",
    "data_labels[data_labels == 4] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6eh7sIquja5t"
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K59PriX4jgBV"
   },
   "source": [
    "We need to create a BERT layer to have access to meta data for the tokenizer (like vocab size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0wry-st-HMN0"
   },
   "outputs": [],
   "source": [
    "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            trainable=False)\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow_hub.keras_layer.KerasLayer"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bert_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bert_layer.resolved_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.training.tracking.tracking.Asset"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bert_layer.resolved_object.vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bert_layer.resolved_object.vocab_file.asset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'/tmp/tfhub_modules/03d6fb3ce1605ad9e5e9ed5346b2fb9623ef4d3d/assets/vocab.txt',\n",
       " True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_file, do_lower_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LggMv7k7Z3Ij"
   },
   "outputs": [],
   "source": [
    "def encode_sentence(sent):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EGfTo5uIa2is"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized tweet #0: [22091, 2860, 2860, 2008, 1005, 1055, 1037, 26352, 5017, 1012, 2017, 2323, 2050, 2288, 2585, 12385, 1997, 2353, 2154, 2000, 2079, 2009, 1012, 1040]\n",
      "Tokenized tweet #1: [2003, 6314, 2008, 2002, 2064, 1005, 1056, 10651, 2010, 9130, 2011, 3793, 2075, 2009, 1012, 1012, 1012, 1998, 2453, 5390, 2004, 1037, 2765, 2082, 2651, 2036, 1012, 27984, 999]\n",
      "Tokenized tweet #2: [1045, 11529, 2094, 2116, 2335, 2005, 1996, 3608, 1012, 3266, 2000, 3828, 1996, 2717, 2175, 2041, 1997, 19202]\n",
      "Tokenized tweet #3: [2026, 2878, 2303, 5683, 2009, 11714, 1998, 2066, 2049, 2006, 2543]\n",
      "Tokenized tweet #4: [2053, 2009, 1005, 1055, 2025, 2022, 3270, 6455, 2012, 2035, 1012, 1045, 1005, 1049, 5506, 1012, 2339, 2572, 1045, 2182, 1029, 2138, 1045, 2064, 1005, 1056, 2156, 2017, 2035, 2058, 2045, 1012]\n",
      "Tokenized tweet #5: [2025, 1996, 2878, 3626]\n",
      "Tokenized tweet #6: [2342, 1037, 8549]\n",
      "Tokenized tweet #7: [4931, 2146, 2051, 2053, 2156, 999, 2748, 1012, 1012, 15811, 1037, 2978, 2069, 1037, 2978, 8840, 2140, 1045, 1005, 1049, 2986, 4283, 2129, 1005, 1055, 2017, 1029]\n",
      "Tokenized tweet #8: [1047, 16780, 2027, 2134, 1005, 1056, 2031, 2009]\n",
      "Tokenized tweet #9: [10861, 2033, 14163, 6906, 1029]\n"
     ]
    }
   ],
   "source": [
    "data_inputs = [encode_sentence(sentence) for sentence in data_clean]\n",
    "\n",
    "# print first 10 tokenized tweets\n",
    "for i, tw in enumerate(data_inputs[:10]):\n",
    "    print(\"Tokenized tweet #%d: %s\" % (i, tw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B-4oGSu5jxUi"
   },
   "source": [
    "### Dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mLg0Z7QOj_YZ"
   },
   "source": [
    "We will create padded batches (so we pad sentences for each batch independently), this way we add the minimum of padding tokens possible. For that, we sort sentences by length, apply padded_batches and then shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HS_f6gWsLfLM"
   },
   "outputs": [],
   "source": [
    "data_with_len = [[sent, data_labels[i], len(sent)]\n",
    "                 for i, sent in enumerate(data_inputs)]\n",
    "random.shuffle(data_with_len)\n",
    "data_with_len.sort(key=lambda x: x[2])\n",
    "sorted_all = [(sent_lab[0], sent_lab[1])\n",
    "              for sent_lab in data_with_len if sent_lab[2] > 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ry0uJJg8lSQR"
   },
   "outputs": [],
   "source": [
    "all_dataset = tf.data.Dataset.from_generator(lambda: sorted_all,\n",
    "                                             output_types=(tf.int32, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset_iterator = iter(all_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "cF74g5hpYzaZ",
    "outputId": "93c6cf91-3cea-4939-c5fd-5824d8bc464b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=int32, numpy=\n",
       " array([ 2045,  2024,  2420,  2127,  2026, 10680,  3428,  4164],\n",
       "       dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(all_dataset_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=int32, numpy=array([1045, 1005, 1049, 2061, 6517, 2157, 2085, 1012], dtype=int32)>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(all_dataset_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZzHAhlfTlrcj"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "all_batched = all_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None,), ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_batched_iterator = iter(all_batched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 8), dtype=int32, numpy=\n",
       " array([[ 2045,  2024,  2420,  2127,  2026, 10680,  3428,  4164],\n",
       "        [ 1045,  1005,  1049,  2061,  6517,  2157,  2085,  1012],\n",
       "        [ 1045,  2514,  2066,  2021,  7880,  2379,  1047,  4481],\n",
       "        [ 2339,  1051,  2339,  2572,  1045,  3110,  2023,  2126],\n",
       "        [ 2108,  2023,  5112,  7840, 19237,  4757,  2015,   999],\n",
       "        [22091,  2860,  2860,  2860,  9152,  6137,  3401,  4402],\n",
       "        [ 4931,  3158, 15549,  4095,  2146,  2051,  2053,  2831],\n",
       "        [ 7697,  1012,  1012,  1012,  1012,  1012,  1012,  1012],\n",
       "        [ 6207,  3573,  1012,  2026,  6097,  2003,  5305,  1012],\n",
       "        [ 2115,  2062, 12476,  1060,  2094,  4283, 22038, 20348],\n",
       "        [ 4283,  2005, 21461,  5254,   999,  1037,  2843,   999],\n",
       "        [ 3331,  2096,  5505,  1999,  4165,  2428,  6881,  1012],\n",
       "        [ 1045,  2031,  1037,  2310, 21194,  2146,  2154,  4826],\n",
       "        [20228,  3126,  2243,  1999,  1996,  7381,  1012,  1012],\n",
       "        [ 1045,  8823,  2205,  2172, 17111,  9541,  9541,  2440],\n",
       "        [ 9260,  2026, 28543,  2609,  5815,  4281,  2189,  2295],\n",
       "        [ 2074,  8271,  2039,  1012,  2018,  1037,  2307,  3637],\n",
       "        [ 4907, 23806,  1012,  9471,  2057, 12482,  3550,  2000],\n",
       "        [ 2183,  1999,  1037,  2252,  6865,  2041,  2007,  2814],\n",
       "        [ 2129,  2024,  2017, 22861,  1029,  2893,  3201,  1029],\n",
       "        [ 3407,  2000,  2022,  2746,  2067,  2000, 16392,  2436],\n",
       "        [ 1045,  2113,  1012,  1012,  1012,  2021,  2073,  1029],\n",
       "        [ 1045,  2064,  1005,  1056,  2156,  2006, 10474,  9766],\n",
       "        [ 2665,  2697,  2007,  2026,  2905,  1998, 12731, 17168],\n",
       "        [ 2026,  3566,  2180,  1005,  1056,  2292,  2033,  2175],\n",
       "        [ 2256,  2482,  3030,  2006,  2256,  2126,  2000,  9925],\n",
       "        [ 3835,  2126,  2203,  1996,  2733,  1012,  1012,  1012],\n",
       "        [ 2061,  5341,  1045,  3335,  9300,  5292,  3270,  3270],\n",
       "        [ 2987,  1005,  1056,  2514,  2204,  2012,  2035,  2140],\n",
       "        [ 3331,  2000, 14470,  2016,  2467, 21250,  2033,  2039],\n",
       "        [ 2672,  2017,  2323, 17021,  2014,  2005,  2204,  1012],\n",
       "        [ 2009,  1005,  1055,  2042,  2045,  2005,  2086,  2085],\n",
       "        [ 8440,  1005,  1056,  2042,  2039, 16616,  9906,  3374],\n",
       "        [ 4365,  1045,  2064,  1005,  1056,  2424,  2505,  1012],\n",
       "        [ 2253,  1999,  1037,  2980,  2250, 13212,  3509,  1029],\n",
       "        [ 2057,  1005,  2128,  3666,  2017,  1012,  1012,  1012],\n",
       "        [ 7459,  2108, 19582,  2011,  2014,  9594,  3762,  1012],\n",
       "        [ 2003,  2012,  2188,   999, 22017,  6806,  2080,   999],\n",
       "        [ 1045,  5223,  2009,  2182,  2000, 17752,  2007,  2009],\n",
       "        [ 5093,  2059,  4895, 23947,  2075,  2013,  2026,  4440],\n",
       "        [ 5305,  1998,  1045,  2031,  2000,  2175,  2041,  2393],\n",
       "        [ 1045,  5121,  2514,  1996,  2293,  2157,  2085,   999],\n",
       "        [ 2024,  2017,  2383,  2919,  4026, 19902,  6203,  1029],\n",
       "        [ 3057, 12575,  2153,  3892,   999,   999,   999,   999],\n",
       "        [ 9852, 18411,  2860,  3407,  5798,   999,   999,   999],\n",
       "        [ 5702,  8785,  2009,  2716,  2026,  4167,  2000, 15044],\n",
       "        [ 2074, 22629,  2014, 16575,  1999,  3888,  4665,  1012],\n",
       "        [17012,  2213,  3075,  2000,  2079,  2026,  8785, 19453],\n",
       "        [ 2821, 23644,  2232,  2053,  1996,  6872,  2351,   999],\n",
       "        [ 2498,  1012,  2074,  4394,  2026, 15876,  2078,  1012],\n",
       "        [ 2031, 17850,  2015,  2000,  3143,  2026,  2744,  3934],\n",
       "        [12476,  4283, 14711,  2097,  4638,  2009,  2041,  1012],\n",
       "        [ 4067,  2017,  2005,  1996,  3582, 27439,  4710,   999],\n",
       "        [ 2821,  4328, 12333, 23644,  2008,  2015,  9643,  1051],\n",
       "        [ 2821,  2092,  1012,  2053,  2047,  3042, 18681,  4826],\n",
       "        [ 3398,   999,  3985,  2067,   999,  6887,  7974,  1012],\n",
       "        [ 3666,  2547,  1998,  5782,  1037,  2047,  2606,  2806],\n",
       "        [ 2023,  3698, 10312,  2035,  2026,  2769,   999,   999],\n",
       "        [ 2054,  4712,  1029,  2106,  1045,  3335,  2242,  1012],\n",
       "        [ 1045,  1005,  1049,  3374,  2008,  1005,  1055,  6659],\n",
       "        [ 2183,  2000, 11937,  3597,  9298,  5162,  2007, 26442],\n",
       "        [ 1045,  2215,  2000,  2156,  2039,  2007,  2017,   999],\n",
       "        [ 2821,  2009,  1005,  1055, 11771,  2108,  2035,  2894],\n",
       "        [ 2821,  6203,  2025,  2000,  7614,  2011,  2151,  3382]],\n",
       "       dtype=int32)>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
       " array([1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "        1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1],\n",
       "       dtype=int32)>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(all_batched_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 8), dtype=int32, numpy=\n",
       " array([[ 2009,  1005,  1055,  2026,  2197,  2733,  1999,  5483],\n",
       "        [ 2025,  3110,  2005,  2147,  2651,  1012,  1012,  1012],\n",
       "        [ 5292,  2050,  2033,  2205,  2012,  2431, 17324,  2050],\n",
       "        [ 4451,  3468,  2098,   999,  2024,  2017,  7929,  1029],\n",
       "        [ 2339,  2876,  1005,  1056,  1045,  2156,  2151,  1029],\n",
       "        [ 2197,  2305,  2001, 12476,  1045,  2293,  2026,  2814],\n",
       "        [12476,  2609,  1012,  1012,  1012,  4283,   999,   999],\n",
       "        [ 1045,  2106,  2025,  2130,  2131,  2000,  5510,  2009],\n",
       "        [ 9779, 23644, 23644,  1996, 24067,  2100, 16373,  4633],\n",
       "        [ 2069,  3426,  2017,  4694,  1005,  1056,  1999,  2009],\n",
       "        [ 1045,  2572,  2061,  5305,  1012,  2793,  2525,  1012],\n",
       "        [ 8915,  5369,  2008,  1005,  1055,  1996,  2391,  1012],\n",
       "        [ 4931, 11317,  1012,  4283,  2153,   999,   999,   999],\n",
       "        [ 2003,  2770,  2659,  1997,  8915,  2232,  9152,  2361],\n",
       "        [ 3241,  2055,  1996,  7036,  2111,  5996,  1999,  4238],\n",
       "        [ 1045,  2031,  2025,  3191,  1996,  2338,  1012,  1012],\n",
       "        [ 9805,  2361,  2550,  2011,  6423,  7031,  2205,  1012],\n",
       "        [ 2061, 16608,  2001,  2307,  2197,  2305,   999,   999],\n",
       "        [ 2026,  7579,  1005,  1055, 24665, 25438,  2989,  1012],\n",
       "        [20868,  6371,  1045,  2963,  8038,  1012,  1012,  1012],\n",
       "        [16780,  1012,  1012,  1012,  1045,  2215,  2028,  2295],\n",
       "        [10261,  2009,  2001,  5958,  2848,  7011, 16567,  6894],\n",
       "        [ 4067,  2017,  2005,  2635,  2051,  2000,  7514,  1012],\n",
       "        [ 2061,  5697,  2000,  2330,  2026, 10474,  4070,   999],\n",
       "        [ 2439,  2012,  9116,  2153,  2339,  2079,  1045, 11891],\n",
       "        [10047,  1999,  1996,  2168,  4049,  2049,  6517,  2428],\n",
       "        [ 1045,  2215, 10885,  4757,   999,   999,   999,   999],\n",
       "        [ 2023,  2003,  2061, 10990,  1048,  2213,  7011,  2080],\n",
       "        [ 1045,  2354,  2017,  2481,  1005,  1056,  5293,  2068],\n",
       "        [ 6289,  6633,  1012,  1012,  1012,  1998,  2061,  1029],\n",
       "        [ 2003,  2006,  2014,  2126,  2000,  2317,  7222,  1012],\n",
       "        [ 5255,  2039,  6490,  2003,  2006,  2006,  2557,  6373],\n",
       "        [ 2026,  2034,  1056, 28394,  2102,  2013, 16233,  2072],\n",
       "        [ 2204,  2005,  2017,  1057,  2024,  1037,  3565, 10670],\n",
       "        [20068,  2050,  2003,  2026,  2397,  2595,  5379,  2767],\n",
       "        [ 2097,  2017, 22404,  2033,  1998,  1037, 18982,  1029],\n",
       "        [ 8044,  2024,  5291,  1999,  1012,  1012,  1012,  1012],\n",
       "        [ 4931, 13007,  2057,  2074,  2915,  2017,  2019, 10373],\n",
       "        [ 2115,  2166,  2003,  1037,  6752,  5292,  3270,   999],\n",
       "        [ 2904,  2026,  3861,  1998,  2085,  2049,  2025,  2551],\n",
       "        [ 7632,  4775,  2129,  1005,  1055,  2009,  2183,  1029],\n",
       "        [ 1045,  1005,  1049,  6069,  2131,  7171,  2157,  2085],\n",
       "        [ 2028,  2062,  2155, 14821,  8840,  2140, 22708,  1012],\n",
       "        [ 2559,  2005,  5841,  1041,  2497,  4161, 10528,  2651],\n",
       "        [ 2293,  3521,  4364,  2074, 10720, 12043,  2015,  1040],\n",
       "        [ 1045,  2428,  4299,  4826,  2347,  1005,  1056,  6928],\n",
       "        [15854,  2080,  7570,  9541,  2057,  2024,  2524,  4563],\n",
       "        [24471,  5603,  2147,  1029,  2008,  2015,  2053,  4569],\n",
       "        [ 2515,  2025,  2215,  2000,  2175,  2000,  2147,  4826],\n",
       "        [ 1038,  2571,  2232, 10201,  2091,  2025,  3110,  2204],\n",
       "        [ 2003,  2183,  2000,  4542,  2182,  1012,  1012,  1012],\n",
       "        [ 4931,  8937,  2031,  4569,  1998,  2655,  2033,  2101],\n",
       "        [ 1045,  1005,  1049,  6517,  1050,  9479,  1999,  2793],\n",
       "        [ 2216,  2020, 12476,  2205,   999,  2926, 26732,  1012],\n",
       "        [ 9107,  1037,  2235,  1048,  2005,  2204,  2214,  2335],\n",
       "        [ 2009,  1005,  1055,  2205,  3835,  2000,  2022,  2503],\n",
       "        [ 5409, 14978,  1999,  4830, 24185, 12190,  6392,  2094],\n",
       "        [10856,  2078,  1045,  4299,  1045,  2001,  2019,  3883],\n",
       "        [ 1045,  2215,  2026,  9081,  2606,  8670,  9468, 19658],\n",
       "        [ 4931,  3071,   999,  1045,  2288,  6731,  2006, 24011],\n",
       "        [ 2025, 29337,  2869,  2748,  1045,  2156,  1057,  6160],\n",
       "        [ 3904,  1997,  2115,  7760,  2412,  7170,  2005,  2033],\n",
       "        [ 2040,  4122,  2000,  2272,  9116,  3892,  1029,  1029],\n",
       "        [ 2216,  2020,  2070, 11937, 21756,  2829,  3111,   999]],\n",
       "       dtype=int32)>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
       " array([0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "        1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "        1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       "       dtype=int32)>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(all_batched_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xrPqJeYpmfcv"
   },
   "outputs": [],
   "source": [
    "NB_BATCHES = math.ceil(len(sorted_all) / BATCH_SIZE)\n",
    "NB_BATCHES_TEST = NB_BATCHES // 10\n",
    "all_batched.shuffle(NB_BATCHES)\n",
    "test_dataset = all_batched.take(NB_BATCHES_TEST)\n",
    "train_dataset = all_batched.skip(NB_BATCHES_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VxONsFVHkFLU"
   },
   "source": [
    "# Stage 3: Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L6DD3k3qPLDQ"
   },
   "outputs": [],
   "source": [
    "class DCNN(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 emb_dim=128,\n",
    "                 nb_filters=50,\n",
    "                 FFN_units=512,\n",
    "                 nb_classes=2,\n",
    "                 dropout_rate=0.1,\n",
    "                 training=False,\n",
    "                 name=\"dcnn\"):\n",
    "        super(DCNN, self).__init__(name=name)\n",
    "        \n",
    "        self.embedding = layers.Embedding(vocab_size,\n",
    "                                          emb_dim)\n",
    "        self.bigram = layers.Conv1D(filters=nb_filters,\n",
    "                                    kernel_size=2,\n",
    "                                    padding=\"valid\",\n",
    "                                    activation=\"relu\")\n",
    "        self.trigram = layers.Conv1D(filters=nb_filters,\n",
    "                                     kernel_size=3,\n",
    "                                     padding=\"valid\",\n",
    "                                     activation=\"relu\")\n",
    "        self.fourgram = layers.Conv1D(filters=nb_filters,\n",
    "                                      kernel_size=4,\n",
    "                                      padding=\"valid\",\n",
    "                                      activation=\"relu\")\n",
    "        self.pool = layers.GlobalMaxPool1D()\n",
    "        \n",
    "        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\n",
    "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
    "        if nb_classes == 2:\n",
    "            self.last_dense = layers.Dense(units=1,\n",
    "                                           activation=\"sigmoid\")\n",
    "        else:\n",
    "            self.last_dense = layers.Dense(units=nb_classes,\n",
    "                                           activation=\"softmax\")\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        x = self.embedding(inputs)\n",
    "        x_1 = self.bigram(x) # batch_size, nb_filters, seq_len-1)\n",
    "        x_1 = self.pool(x_1) # (batch_size, nb_filters)\n",
    "        x_2 = self.trigram(x) # batch_size, nb_filters, seq_len-2)\n",
    "        x_2 = self.pool(x_2) # (batch_size, nb_filters)\n",
    "        x_3 = self.fourgram(x) # batch_size, nb_filters, seq_len-3)\n",
    "        x_3 = self.pool(x_3) # (batch_size, nb_filters)\n",
    "        \n",
    "        merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3 * nb_filters)\n",
    "        merged = self.dense_1(merged)\n",
    "        merged = self.dropout(merged, training)\n",
    "        output = self.last_dense(merged)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vSix1l4jkIxp"
   },
   "source": [
    "# Stage 4: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lhfUFvWEPOIf"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(tokenizer.vocab)\n",
    "EMB_DIM = 200\n",
    "NB_FILTERS = 100\n",
    "FFN_UNITS = 256\n",
    "NB_CLASSES = 2\n",
    "\n",
    "DROPOUT_RATE = 0.2\n",
    "\n",
    "NB_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VMtdiWmwv6rD"
   },
   "outputs": [],
   "source": [
    "Dcnn = DCNN(vocab_size=VOCAB_SIZE,\n",
    "            emb_dim=EMB_DIM,\n",
    "            nb_filters=NB_FILTERS,\n",
    "            FFN_units=FFN_UNITS,\n",
    "            nb_classes=NB_CLASSES,\n",
    "            dropout_rate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6apbd7FrwPYo"
   },
   "outputs": [],
   "source": [
    "if NB_CLASSES == 2:\n",
    "    Dcnn.compile(loss=\"binary_crossentropy\",\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=[\"accuracy\"])\n",
    "else:\n",
    "    Dcnn.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=[\"sparse_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "78cceSGCw1XC",
    "outputId": "7a65cd56-f31f-4133-f06b-40925ae47750"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./ckpt/\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print(\"Latest checkpoint restored!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2YIF5trzx7RA"
   },
   "outputs": [],
   "source": [
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        ckpt_manager.save()\n",
    "        print(\"Checkpoint saved at {}.\".format(checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "WrT8oWZzQNmW",
    "outputId": "bb67b680-42ec-4f0d-afbf-6a8eecaa54fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  18598/Unknown - 620s 33ms/step - loss: 0.4263 - accuracy: 0.8033Checkpoint saved at ./ckpt/.\n",
      "18598/18598 [==============================] - 620s 33ms/step - loss: 0.4263 - accuracy: 0.8033\n",
      "Epoch 2/5\n",
      "18596/18598 [============================>.] - ETA: 0s - loss: 0.3730 - accuracy: 0.8340Checkpoint saved at ./ckpt/.\n",
      "18598/18598 [==============================] - 584s 31ms/step - loss: 0.3730 - accuracy: 0.8340\n",
      "Epoch 3/5\n",
      "18597/18598 [============================>.] - ETA: 0s - loss: 0.3230 - accuracy: 0.8601Checkpoint saved at ./ckpt/.\n",
      "18598/18598 [==============================] - 583s 31ms/step - loss: 0.3230 - accuracy: 0.8600\n",
      "Epoch 4/5\n",
      "18597/18598 [============================>.] - ETA: 0s - loss: 0.2734 - accuracy: 0.8835Checkpoint saved at ./ckpt/.\n",
      "18598/18598 [==============================] - 586s 32ms/step - loss: 0.2734 - accuracy: 0.8835\n",
      "Epoch 5/5\n",
      "18597/18598 [============================>.] - ETA: 0s - loss: 0.2319 - accuracy: 0.9020Checkpoint saved at ./ckpt/.\n",
      "18598/18598 [==============================] - 582s 31ms/step - loss: 0.2319 - accuracy: 0.9020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f17028881d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dcnn.fit(train_dataset,\n",
    "         epochs=NB_EPOCHS,\n",
    "         callbacks=[MyCustomCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dcnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  6104400   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              multiple                  40100     \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            multiple                  60100     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            multiple                  80100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  77056     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  257       \n",
      "=================================================================\n",
      "Total params: 6,362,013\n",
      "Trainable params: 6,362,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Dcnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3IiDW919kQQK"
   },
   "source": [
    "# Stage 5: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MthhNfnG1TPV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2066/Unknown - 18s 9ms/step - loss: 0.4937 - accuracy: 0.8281[0.49369014525517374, 0.82805693]\n"
     ]
    }
   ],
   "source": [
    "results = Dcnn.evaluate(test_dataset)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-jrRvtl1xuk"
   },
   "outputs": [],
   "source": [
    "def get_prediction(sentence):\n",
    "    tokens = encode_sentence(sentence)\n",
    "    inputs = tf.expand_dims(tokens, 0)\n",
    "\n",
    "    output = Dcnn(inputs, training=False)\n",
    "\n",
    "    sentiment = math.floor(output*2)\n",
    "\n",
    "    if sentiment == 0:\n",
    "        print(\"Ouput of the model: {}\\nPredicted sentiment: negative.\".format(output))\n",
    "    elif sentiment == 1:\n",
    "        print(\"Ouput of the model: {}\\nPredicted sentiment: positive.\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "wMyVjgSt3Nze",
    "outputId": "d5d3f432-5f6f-4103-fb58-a986278dac03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: He is a good teacher!\n",
      "Ouput of the model: [[0.99985445]]\n",
      "Predicted sentiment: positive.\n",
      "Input sentence: It's an awesome movie!\n",
      "Ouput of the model: [[0.99999595]]\n",
      "Predicted sentiment: positive.\n",
      "Input sentence: it's the worst movie I've ever seen\n",
      "Ouput of the model: [[0.11321876]]\n",
      "Predicted sentiment: negative.\n",
      "Input sentence: that's bullshit\n",
      "Ouput of the model: [[0.01931121]]\n",
      "Predicted sentiment: negative.\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\"He is a good teacher!\",\n",
    "                  \"It's an awesome movie!\",\n",
    "                  \"it's the worst movie I've ever seen\",\n",
    "                  \"that's bullshit\"]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    print(\"Input sentence: {}\".format(sentence))\n",
    "    get_prediction(sentence)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "B-4oGSu5jxUi",
    "VxONsFVHkFLU",
    "vSix1l4jkIxp"
   ],
   "name": "Bert_tokenizer",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
