{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1tadN4hSCP9p"
   },
   "source": [
    "# Stage 1: Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EUU4TlmoFMZ_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.1.0\n",
      "TensorFlow Hub Version: 0.8.0\n",
      "bert-for-tf2 Version: 0.14.4\n",
      "Query free memories from all GPUs: nvidia-smi --query-gpu=memory.free --format=csv,noheader,nounits\n",
      "Free memory list (MB): [11018, 11176, 11176, 11159]\n",
      "Query names of processes running on the GPU index 0: nvidia-smi --query-compute-apps=process_name --format=csv,noheader,nounits --id=0\n",
      "Names of processes running on the GPU index 0: []\n",
      "Query names of processes running on the GPU index 1: nvidia-smi --query-compute-apps=process_name --format=csv,noheader,nounits --id=1\n",
      "Names of processes running on the GPU index 1: []\n",
      "Query names of processes running on the GPU index 2: nvidia-smi --query-compute-apps=process_name --format=csv,noheader,nounits --id=2\n",
      "Names of processes running on the GPU index 2: []\n",
      "Query names of processes running on the GPU index 3: nvidia-smi --query-compute-apps=process_name --format=csv,noheader,nounits --id=3\n",
      "Names of processes running on the GPU index 3: []\n",
      "Left next 1 GPU(s) unmasked: [2] (from [2 0 3 1] available)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "\n",
    "import bert\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"TensorFlow Hub Version:\", hub.__version__)\n",
    "print(\"bert-for-tf2 Version:\", bert.__version__)\n",
    "\n",
    "from utility import mask_busy_gpus\n",
    "mask_busy_gpus(1)  # randomly select 1 unused GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j6ZbE2lPDIFL"
   },
   "source": [
    "# Stage 2: Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T9S77lewDNE1"
   },
   "source": [
    "## Loading files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J7GET0xsDSDc"
   },
   "source": [
    "We import files from our personal Google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "slnILsqwGxTX"
   },
   "outputs": [],
   "source": [
    "cols = [\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n",
    "data = pd.read_csv(\"./data/train.csv\",\n",
    "                   header=None,\n",
    "                   names=cols,\n",
    "                   engine=\"python\",\n",
    "                   encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "REdK4z4YG9kZ"
   },
   "outputs": [],
   "source": [
    "data.drop([\"id\", \"date\", \"query\", \"user\"],\n",
    "          axis=1,\n",
    "          inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lz2g61evDZb4"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LCyy4babDrI8"
   },
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UEyorQS_HArn"
   },
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    tweet = BeautifulSoup(tweet, \"lxml\").get_text()\n",
    "    # Removing the @\n",
    "    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\n",
    "    # Removing the URL links\n",
    "    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\n",
    "    # Keeping only letters\n",
    "    tweet = re.sub(r\"[^a-zA-Z.!?']\", ' ', tweet)\n",
    "    # Removing additional whitespaces\n",
    "    tweet = re.sub(r\" +\", ' ', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3BlbZpy0HHiV"
   },
   "outputs": [],
   "source": [
    "data_clean = [clean_tweet(tweet) for tweet in data.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H6SOj46BHKEk"
   },
   "outputs": [],
   "source": [
    "data_labels = data.sentiment.values\n",
    "data_labels[data_labels == 4] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MJa3YWeJD1gM"
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MUaCPqqBD7kQ"
   },
   "source": [
    "We need to create a BERT layer to have access to meta data for the tokenizer (like vocab size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0wry-st-HMN0"
   },
   "outputs": [],
   "source": [
    "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            trainable=False)\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HMVarTJpELyK"
   },
   "source": [
    "We only use the first sentence for BERT inputs so we add the CLS token at the beginning and the SEP token at the end of each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v-JkZt9NduoC"
   },
   "outputs": [],
   "source": [
    "def encode_sentence(sent):\n",
    "    return [\"[CLS]\"] + tokenizer.tokenize(sent) + [\"[SEP]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pel_Uk6Ic4xB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized tweet #0: ['[CLS]', 'aw', '##w', '##w', 'that', \"'\", 's', 'a', 'bum', '##mer', '.', 'you', 'should', '##a', 'got', 'david', 'carr', 'of', 'third', 'day', 'to', 'do', 'it', '.', 'd', '[SEP]']\n",
      "Tokenized tweet #1: ['[CLS]', 'is', 'upset', 'that', 'he', 'can', \"'\", 't', 'update', 'his', 'facebook', 'by', 'text', '##ing', 'it', '.', '.', '.', 'and', 'might', 'cry', 'as', 'a', 'result', 'school', 'today', 'also', '.', 'blah', '!', '[SEP]']\n",
      "Tokenized tweet #2: ['[CLS]', 'i', 'dive', '##d', 'many', 'times', 'for', 'the', 'ball', '.', 'managed', 'to', 'save', 'the', 'rest', 'go', 'out', 'of', 'bounds', '[SEP]']\n",
      "Tokenized tweet #3: ['[CLS]', 'my', 'whole', 'body', 'feels', 'it', '##chy', 'and', 'like', 'its', 'on', 'fire', '[SEP]']\n",
      "Tokenized tweet #4: ['[CLS]', 'no', 'it', \"'\", 's', 'not', 'be', '##ha', '##ving', 'at', 'all', '.', 'i', \"'\", 'm', 'mad', '.', 'why', 'am', 'i', 'here', '?', 'because', 'i', 'can', \"'\", 't', 'see', 'you', 'all', 'over', 'there', '.', '[SEP]']\n",
      "Tokenized tweet #5: ['[CLS]', 'not', 'the', 'whole', 'crew', '[SEP]']\n",
      "Tokenized tweet #6: ['[CLS]', 'need', 'a', 'hug', '[SEP]']\n",
      "Tokenized tweet #7: ['[CLS]', 'hey', 'long', 'time', 'no', 'see', '!', 'yes', '.', '.', 'rains', 'a', 'bit', 'only', 'a', 'bit', 'lo', '##l', 'i', \"'\", 'm', 'fine', 'thanks', 'how', \"'\", 's', 'you', '?', '[SEP]']\n",
      "Tokenized tweet #8: ['[CLS]', 'k', 'nope', 'they', 'didn', \"'\", 't', 'have', 'it', '[SEP]']\n",
      "Tokenized tweet #9: ['[CLS]', 'que', 'me', 'mu', '##era', '?', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "data_inputs = [encode_sentence(sentence) for sentence in data_clean]\n",
    "\n",
    "# print first 10 tokenized tweets\n",
    "for i, tw in enumerate(data_inputs[:10]):\n",
    "    print(\"Tokenized tweet #%d: %s\" % (i, tw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z32MeEwnkCB8"
   },
   "source": [
    "### Dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cUVc83VNEcW9"
   },
   "source": [
    "We need to create the 3 different inputs for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmW9JZLJaxww"
   },
   "outputs": [],
   "source": [
    "def get_ids(tokens):\n",
    "    return tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "def get_mask(tokens):\n",
    "    return np.char.not_equal(tokens, \"[PAD]\").astype(int)\n",
    "\n",
    "def get_segments(tokens):\n",
    "    seg_ids = []\n",
    "    current_seg_id = 0\n",
    "    for tok in tokens:\n",
    "        seg_ids.append(current_seg_id)\n",
    "        if tok == \"[SEP]\":\n",
    "            current_seg_id = 1-current_seg_id # turns 1 into 0 and vice versa\n",
    "    return seg_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x06fFPFtFqVK"
   },
   "source": [
    "We will create padded batches (so we pad sentences for each batch independently), this way we add the minimum of padding tokens possible. For that, we sort sentences by length, apply padded_batches and then shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjAVGCwlb6F8"
   },
   "outputs": [],
   "source": [
    "data_with_len = [[sent, data_labels[i], len(sent)]\n",
    "                 for i, sent in enumerate(data_inputs)]\n",
    "random.shuffle(data_with_len)\n",
    "data_with_len.sort(key=lambda x: x[2])\n",
    "sorted_all = [([get_ids(sent_lab[0]),\n",
    "                get_mask(sent_lab[0]),\n",
    "                get_segments(sent_lab[0])],\n",
    "               sent_lab[1])\n",
    "              for sent_lab in data_with_len if sent_lab[2] > 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZkMiqmzsfo6a"
   },
   "outputs": [],
   "source": [
    "# A list is a type of iterator so it can be used as generator for a dataset\n",
    "all_dataset = tf.data.Dataset.from_generator(lambda: sorted_all,\n",
    "                                             output_types=(tf.int32, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkGWlzeOfos6"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "all_batched = all_dataset.padded_batch(BATCH_SIZE,\n",
    "                                       padded_shapes=((3, None), ()),\n",
    "                                       padding_values=(0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5aA7it--hHl4"
   },
   "outputs": [],
   "source": [
    "NB_BATCHES = math.ceil(len(sorted_all) / BATCH_SIZE)\n",
    "NB_BATCHES_TEST = NB_BATCHES // 10\n",
    "all_batched.shuffle(NB_BATCHES)\n",
    "test_dataset = all_batched.take(NB_BATCHES_TEST)\n",
    "train_dataset = all_batched.skip(NB_BATCHES_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "X4QCPok7aEM_",
    "outputId": "44d6e2b9-8688-42ea-92c3-07692e03bb61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(256, 3, 10), dtype=int32, numpy=\n",
       " array([[[  101,  1045,  2123, ...,  4431,  1012,   102],\n",
       "         [    1,     1,     1, ...,     1,     1,     1],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]],\n",
       " \n",
       "        [[  101,  2865, 11360, ...,  3980,  1012,   102],\n",
       "         [    1,     1,     1, ...,     1,     1,     1],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]],\n",
       " \n",
       "        [[  101,  2821,  2158, ...,  2157,  2085,   102],\n",
       "         [    1,     1,     1, ...,     1,     1,     1],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  101,  1045,  4299, ...,  3861,  5653,   102],\n",
       "         [    1,     1,     1, ...,     1,     1,     1],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]],\n",
       " \n",
       "        [[  101,  4487,  9284, ...,  2006,  1012,   102],\n",
       "         [    1,     1,     1, ...,     1,     1,     1],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]],\n",
       " \n",
       "        [[  101,  1045,  2134, ...,  2156,  2009,   102],\n",
       "         [    1,     1,     1, ...,     1,     1,     1],\n",
       "         [    0,     0,     0, ...,     0,     0,     0]]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(256,), dtype=int32, numpy=\n",
       " array([0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "        0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "        0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "        1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "        1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "        0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "        1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "        1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "        1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "        0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0], dtype=int32)>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N2pxAPFxGe8r"
   },
   "source": [
    "# Stage 3: Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L6DD3k3qPLDQ"
   },
   "outputs": [],
   "source": [
    "class DCNNBERTEmbedding(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 nb_filters=50,\n",
    "                 FFN_units=512,\n",
    "                 nb_classes=2,\n",
    "                 dropout_rate=0.1,\n",
    "                 name=\"dcnn\"):\n",
    "        super(DCNNBERTEmbedding, self).__init__(name=name)\n",
    "        \n",
    "        self.bert_layer = hub.KerasLayer(\n",
    "            \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "            trainable=False)\n",
    "\n",
    "        self.bigram = layers.Conv1D(filters=nb_filters,\n",
    "                                    kernel_size=2,\n",
    "                                    padding=\"valid\",\n",
    "                                    activation=\"relu\")\n",
    "        self.trigram = layers.Conv1D(filters=nb_filters,\n",
    "                                     kernel_size=3,\n",
    "                                     padding=\"valid\",\n",
    "                                     activation=\"relu\")\n",
    "        self.fourgram = layers.Conv1D(filters=nb_filters,\n",
    "                                      kernel_size=4,\n",
    "                                      padding=\"valid\",\n",
    "                                      activation=\"relu\")\n",
    "        self.pool = layers.GlobalMaxPool1D()\n",
    "        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\n",
    "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
    "        if nb_classes == 2:\n",
    "            self.last_dense = layers.Dense(units=1,\n",
    "                                           activation=\"sigmoid\")\n",
    "        else:\n",
    "            self.last_dense = layers.Dense(units=nb_classes,\n",
    "                                           activation=\"softmax\")\n",
    "    \n",
    "    def embed_with_bert(self, all_tokens):\n",
    "        _, embs = self.bert_layer([all_tokens[:, 0, :],\n",
    "                                   all_tokens[:, 1, :],\n",
    "                                   all_tokens[:, 2, :]])\n",
    "        return embs\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        x = self.embed_with_bert(inputs)\n",
    "\n",
    "        x_1 = self.bigram(x)\n",
    "        x_1 = self.pool(x_1)\n",
    "        x_2 = self.trigram(x)\n",
    "        x_2 = self.pool(x_2)\n",
    "        x_3 = self.fourgram(x)\n",
    "        x_3 = self.pool(x_3)\n",
    "        \n",
    "        merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3 * nb_filters)\n",
    "        merged = self.dense_1(merged)\n",
    "        merged = self.dropout(merged, training)\n",
    "        output = self.last_dense(merged)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hsWpzQz2IQvJ"
   },
   "source": [
    "# Stage 4: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lhfUFvWEPOIf"
   },
   "outputs": [],
   "source": [
    "NB_FILTERS = 100\n",
    "FFN_UNITS = 256\n",
    "NB_CLASSES = 2\n",
    "\n",
    "DROPOUT_RATE = 0.2\n",
    "\n",
    "NB_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5HPbZ72KPPnX"
   },
   "outputs": [],
   "source": [
    "Dcnn = DCNNBERTEmbedding(nb_filters=NB_FILTERS,\n",
    "                         FFN_units=FFN_UNITS,\n",
    "                         nb_classes=NB_CLASSES,\n",
    "                         dropout_rate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'this', 'is', 'a', 'test', 'sentence', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "test_sentence = encode_sentence(\"This is a test sentence.\")\n",
    "print(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
       " array([[-0.9315209 , -0.4680269 , -0.82146406,  0.8277694 ,  0.6000099 ,\n",
       "         -0.16843943,  0.9150352 ,  0.30513808, -0.7012272 , -0.9999936 ,\n",
       "         -0.15500334,  0.86598194,  0.98336756,  0.4282941 ,  0.9460871 ,\n",
       "         -0.7464459 , -0.19611955, -0.61434007,  0.33048514, -0.7218173 ,\n",
       "          0.6563666 ,  0.9999436 ,  0.40550685,  0.35627264,  0.46196997,\n",
       "          0.9589823 , -0.68519145,  0.9341063 ,  0.96247625,  0.7443774 ,\n",
       "         -0.7930337 ,  0.16870758, -0.98790234, -0.20499817, -0.86913955,\n",
       "         -0.99292016,  0.42868108, -0.7316571 , -0.01420928, -0.00326651,\n",
       "         -0.91100085,  0.33216992,  0.99997747, -0.53717005,  0.38309842,\n",
       "         -0.34688258, -0.99999994,  0.2892068 , -0.9086961 ,  0.8077502 ,\n",
       "          0.8028393 ,  0.7044046 ,  0.21862246,  0.5343277 ,  0.539189  ,\n",
       "         -0.28988   , -0.07221564,  0.18363605, -0.3172046 , -0.6191995 ,\n",
       "         -0.66389024,  0.38110268, -0.65375316, -0.9328118 ,  0.6840205 ,\n",
       "          0.69019145, -0.160122  , -0.33875874, -0.19412649, -0.03323338,\n",
       "          0.91568977,  0.3194194 , -0.22256814, -0.82491344,  0.57105047,\n",
       "          0.294378  , -0.64717376,  1.        , -0.5067713 , -0.9775307 ,\n",
       "          0.7240696 ,  0.6601689 ,  0.60298336, -0.09442982,  0.45514205,\n",
       "         -1.        ,  0.6118671 , -0.14029418, -0.9882792 ,  0.13284245,\n",
       "          0.52983296, -0.2937697 ,  0.69153637,  0.649853  , -0.6307348 ,\n",
       "         -0.43467572, -0.38738513, -0.69247806, -0.22485387, -0.26152483,\n",
       "          0.13538459, -0.37928918, -0.36270496, -0.39853472,  0.34073824,\n",
       "         -0.51482105, -0.5103736 ,  0.6273294 ,  0.14285159,  0.7714292 ,\n",
       "          0.47849727, -0.38231337,  0.4713731 , -0.9572746 ,  0.6663298 ,\n",
       "         -0.40831575, -0.98667985, -0.61023784, -0.9838421 ,  0.76038843,\n",
       "         -0.10744426, -0.26524034,  0.9729566 , -0.3043299 ,  0.3703153 ,\n",
       "         -0.1669448 , -0.7938065 , -1.        , -0.43098438, -0.5728414 ,\n",
       "         -0.16640684, -0.2888105 , -0.9782414 , -0.960437  ,  0.6406281 ,\n",
       "          0.9694347 ,  0.25759503,  0.99989474, -0.33645418,  0.94426537,\n",
       "         -0.19456096, -0.52815807,  0.24858236, -0.46145156,  0.7536104 ,\n",
       "          0.46201098, -0.71399313,  0.2241882 , -0.2529888 ,  0.2584809 ,\n",
       "         -0.62898695, -0.34182662, -0.76863754, -0.9254805 , -0.4181651 ,\n",
       "          0.94860536, -0.3504559 , -0.8596893 ,  0.25444156, -0.2977696 ,\n",
       "         -0.37320724,  0.87188447,  0.71419555,  0.40545955, -0.24789049,\n",
       "          0.4841554 ,  0.4712074 ,  0.5608332 , -0.9133936 ,  0.17662115,\n",
       "          0.5095305 , -0.28955054, -0.824116  , -0.9786069 , -0.41487816,\n",
       "          0.552433  ,  0.9867393 ,  0.78112423,  0.32050928,  0.7331688 ,\n",
       "         -0.41852394,  0.5680796 , -0.94786036,  0.9818009 , -0.15565296,\n",
       "          0.30462107, -0.56304604,  0.44323832, -0.9131085 ,  0.14495309,\n",
       "          0.8782707 , -0.41461578, -0.87442255, -0.08131886, -0.5688703 ,\n",
       "         -0.45592582, -0.6997613 ,  0.5473827 , -0.3989455 , -0.3985336 ,\n",
       "         -0.1667235 ,  0.93640697,  0.98354584,  0.7766899 , -0.0405379 ,\n",
       "          0.635407  , -0.891493  , -0.4905164 ,  0.13423717,  0.332025  ,\n",
       "          0.09386133,  0.992665  , -0.6396828 , -0.17174934, -0.95259917,\n",
       "         -0.98441565, -0.04467519, -0.9015343 , -0.10647143, -0.7134602 ,\n",
       "          0.63699555, -0.27919686,  0.40500605,  0.42602497, -0.9872139 ,\n",
       "         -0.8747962 ,  0.38052347, -0.47169468,  0.527959  , -0.30051348,\n",
       "          0.8545538 ,  0.90533704, -0.68861145,  0.7505251 ,  0.9374538 ,\n",
       "         -0.7781867 , -0.8025094 ,  0.86305   , -0.35248753,  0.92108154,\n",
       "         -0.6928729 ,  0.9941046 ,  0.83686864,  0.64423263, -0.9317043 ,\n",
       "         -0.6871544 , -0.93213296, -0.6520123 , -0.15804859, -0.04018549,\n",
       "          0.8025629 ,  0.6868869 ,  0.36344796,  0.35857874, -0.59611833,\n",
       "          0.9983526 , -0.86507225, -0.9524429 , -0.15921949, -0.12520593,\n",
       "         -0.9890963 ,  0.820248  ,  0.2633893 ,  0.13744406, -0.5227324 ,\n",
       "         -0.6678127 , -0.95977604,  0.8934536 ,  0.1681281 ,  0.99205655,\n",
       "         -0.5269953 , -0.9208499 , -0.66397923, -0.91234076, -0.12512784,\n",
       "         -0.32213542, -0.07666262, -0.11671457, -0.9555572 ,  0.54868495,\n",
       "          0.61639607,  0.53210044, -0.7377918 ,  0.998851  ,  0.99999976,\n",
       "          0.9783806 ,  0.89460534,  0.92847496, -0.99948114, -0.4438644 ,\n",
       "          0.9999974 , -0.97793144, -1.        , -0.95121986, -0.7094458 ,\n",
       "          0.44840917, -1.        , -0.23127791, -0.02241887, -0.90368646,\n",
       "          0.49438676,  0.9805823 ,  0.9944691 , -1.        ,  0.8823346 ,\n",
       "          0.9437014 , -0.6771352 ,  0.8619405 , -0.48717287,  0.9745431 ,\n",
       "          0.66023433,  0.5808369 , -0.24689119,  0.38457695, -0.8890701 ,\n",
       "         -0.8865006 , -0.52270436, -0.58669305,  0.9963065 ,  0.14493094,\n",
       "         -0.79081964, -0.9235181 ,  0.514417  , -0.02010804, -0.02811817,\n",
       "         -0.9589295 , -0.2412895 ,  0.25068864,  0.77180284,  0.23772505,\n",
       "          0.2985768 , -0.7968924 ,  0.3334079 ,  0.12383606,  0.46648085,\n",
       "          0.70224077, -0.9496753 , -0.6642797 ,  0.1088801 , -0.34414265,\n",
       "         -0.4703743 , -0.9682404 ,  0.9695974 , -0.37464797,  0.732243  ,\n",
       "          1.        ,  0.2231926 , -0.8890369 ,  0.6075846 ,  0.25555262,\n",
       "         -0.6640781 ,  1.        ,  0.72136617, -0.9832582 , -0.6322935 ,\n",
       "          0.64722264, -0.6045111 , -0.6286208 ,  0.99953705, -0.34342548,\n",
       "         -0.58244336, -0.28321686,  0.9692935 , -0.9907157 ,  0.9892856 ,\n",
       "         -0.9199915 , -0.96636754,  0.96806633,  0.9398823 , -0.44786346,\n",
       "         -0.7776833 ,  0.15340053, -0.738204  ,  0.3188546 , -0.9685172 ,\n",
       "          0.7026342 ,  0.5267368 , -0.15426014,  0.90090656, -0.8620508 ,\n",
       "         -0.63417494,  0.46971047, -0.47290245,  0.19607055,  0.92579806,\n",
       "          0.5168812 , -0.29852593,  0.06365262, -0.29606104, -0.6267575 ,\n",
       "         -0.9695621 ,  0.50096124,  1.        , -0.12688793,  0.5745053 ,\n",
       "         -0.4397695 , -0.11143299, -0.12845737,  0.60112053,  0.6268544 ,\n",
       "         -0.33287865, -0.9021467 ,  0.7304739 , -0.9622412 , -0.98604006,\n",
       "          0.755479  ,  0.2402763 , -0.36801246,  0.99999464,  0.5104122 ,\n",
       "          0.1519238 ,  0.30635285,  0.9376614 ,  0.08057621,  0.5396097 ,\n",
       "          0.7109475 ,  0.97816217, -0.34424227,  0.623401  ,  0.88949716,\n",
       "         -0.8145309 , -0.33847013, -0.76239467, -0.03439378, -0.9391466 ,\n",
       "          0.0424904 , -0.95745295,  0.96921486,  0.7757613 ,  0.446159  ,\n",
       "          0.25808063,  0.6968639 ,  1.        , -0.32784963,  0.66950864,\n",
       "         -0.2585017 ,  0.8409222 , -0.9994461 , -0.87766814, -0.3966942 ,\n",
       "         -0.07792294, -0.6265423 , -0.37361866,  0.28378645, -0.9620918 ,\n",
       "          0.6510514 ,  0.52868915, -0.9891829 , -0.9894943 ,  0.03666651,\n",
       "          0.8306798 ,  0.08950146, -0.96555734, -0.65586996, -0.65502465,\n",
       "          0.50678074, -0.36145863, -0.92668575,  0.05600061, -0.37309286,\n",
       "          0.47747287, -0.34293827,  0.6209458 ,  0.78715   ,  0.67126185,\n",
       "         -0.7775128 , -0.14101855, -0.0847418 , -0.79964596,  0.8416345 ,\n",
       "         -0.86772823, -0.82681024, -0.1601496 ,  1.        , -0.64949214,\n",
       "          0.8901951 ,  0.77610004,  0.76119506, -0.282549  ,  0.20793192,\n",
       "          0.899032  ,  0.27122793, -0.6780435 , -0.7300613 , -0.5886396 ,\n",
       "         -0.39907068,  0.71671295,  0.5114422 ,  0.7147322 ,  0.8435725 ,\n",
       "          0.76666737,  0.08063508, -0.06106082,  0.08966183,  0.99970275,\n",
       "         -0.11291227, -0.30814603, -0.6458416 , -0.11054711, -0.35299295,\n",
       "         -0.15162137,  1.        ,  0.402118  ,  0.24441479, -0.9891771 ,\n",
       "         -0.7801658 , -0.93027633,  0.99999887,  0.80927336, -0.8809955 ,\n",
       "          0.7396146 ,  0.39988297, -0.14457281,  0.77815926, -0.24208114,\n",
       "         -0.23233268,  0.16907033,  0.138542  ,  0.9517689 , -0.5814404 ,\n",
       "         -0.9590666 , -0.6546234 ,  0.43562508, -0.96895146,  0.9997662 ,\n",
       "         -0.68367934, -0.3464311 , -0.43455145, -0.09667658,  0.53700876,\n",
       "         -0.01588721, -0.9788146 , -0.23412591,  0.11479992,  0.96794283,\n",
       "          0.28235534, -0.63684154, -0.92150164,  0.62418914,  0.6570847 ,\n",
       "         -0.7559393 , -0.92361516,  0.96445215, -0.98205566,  0.48450732,\n",
       "          1.        ,  0.45061788, -0.2952971 ,  0.29959568, -0.6111803 ,\n",
       "          0.35473478, -0.00388714,  0.7632892 , -0.9638757 , -0.41246217,\n",
       "         -0.28726742,  0.36281654, -0.23680544, -0.14882061,  0.68079996,\n",
       "          0.16734074, -0.55899954, -0.6202977 , -0.19812337,  0.48789477,\n",
       "          0.83982754, -0.1969158 , -0.19468343,  0.08632863, -0.22159076,\n",
       "         -0.9223253 , -0.35142738, -0.49521273, -0.999974  ,  0.7042078 ,\n",
       "         -1.        ,  0.43093383,  0.11919986, -0.25871772,  0.83179116,\n",
       "          0.5701964 ,  0.75022686, -0.7800911 , -0.67514586,  0.49795252,\n",
       "          0.786987  , -0.3570069 , -0.04059703, -0.73601747,  0.34156066,\n",
       "         -0.12437584,  0.27851418, -0.48364916,  0.8078009 , -0.24250413,\n",
       "          1.        ,  0.15743326, -0.69827497, -0.9787734 ,  0.29321453,\n",
       "         -0.32621825,  0.99999994, -0.9452744 , -0.9496996 ,  0.38455126,\n",
       "         -0.75762707, -0.8420244 ,  0.36774412,  0.09202521, -0.7358264 ,\n",
       "         -0.89533186,  0.9662736 ,  0.89842385, -0.6131524 ,  0.56315005,\n",
       "         -0.3207969 , -0.6403434 , -0.00910421,  0.72423196,  0.98461854,\n",
       "          0.5935706 ,  0.9428986 ,  0.15465298, -0.41627   ,  0.97619796,\n",
       "          0.2964459 ,  0.6118741 ,  0.12163351,  1.        ,  0.34764713,\n",
       "         -0.9446242 ,  0.33322203, -0.99085927, -0.23837827, -0.9678111 ,\n",
       "          0.3236481 ,  0.25975323,  0.9051535 , -0.3622543 ,  0.9635342 ,\n",
       "         -0.6775984 ,  0.0787449 , -0.24535353, -0.22387272,  0.37801054,\n",
       "         -0.92632014, -0.9866034 , -0.9821999 ,  0.55967844, -0.51799285,\n",
       "         -0.19876651,  0.3038203 ,  0.2021765 ,  0.4928432 ,  0.41615185,\n",
       "         -1.        ,  0.94087416,  0.4969792 ,  0.8486329 ,  0.95112705,\n",
       "          0.5589083 ,  0.5351201 ,  0.28268194, -0.9846407 , -0.98375016,\n",
       "         -0.42358494, -0.38905597,  0.79504955,  0.60998356,  0.9108247 ,\n",
       "          0.43725836, -0.4839417 , -0.5892397 , -0.58385545, -0.6680881 ,\n",
       "         -0.9913046 ,  0.42891216, -0.45730788, -0.9693893 ,  0.96197754,\n",
       "         -0.02640119, -0.21643177,  0.13969621, -0.67739487,  0.9248755 ,\n",
       "          0.84806   ,  0.43654764,  0.07230671,  0.5481381 ,  0.89340866,\n",
       "          0.9721538 ,  0.98791933, -0.7343322 ,  0.8548955 , -0.3827477 ,\n",
       "          0.5795001 ,  0.61391807, -0.9369277 ,  0.22742712,  0.464613  ,\n",
       "         -0.4185901 ,  0.2544278 , -0.27264068, -0.9740663 ,  0.6813834 ,\n",
       "         -0.27200893,  0.5093878 , -0.43459406,  0.11497333, -0.44142342,\n",
       "         -0.27476248, -0.85074556, -0.645119  ,  0.6667018 ,  0.42601144,\n",
       "          0.9055775 ,  0.78258365, -0.09318139, -0.753162  , -0.24331458,\n",
       "         -0.7260759 , -0.92870647,  0.9436349 , -0.06033525, -0.2943777 ,\n",
       "          0.7055521 ,  0.01909296,  0.83593196,  0.11268972, -0.47424778,\n",
       "         -0.29832512, -0.8351074 ,  0.9103157 , -0.5531023 , -0.60141134,\n",
       "         -0.51878226,  0.6782584 ,  0.35233012,  0.99994934, -0.7267263 ,\n",
       "         -0.78104067, -0.35974064, -0.37239254,  0.41810402, -0.44256443,\n",
       "         -1.        ,  0.46937388, -0.3105698 ,  0.63211954, -0.44375548,\n",
       "          0.64241064, -0.29330462, -0.98423547, -0.22292642,  0.6064023 ,\n",
       "          0.62299776, -0.57646567, -0.4901858 ,  0.6245282 ,  0.21007225,\n",
       "          0.9123665 ,  0.8997135 , -0.3970067 ,  0.18463774,  0.66705894,\n",
       "         -0.78250873, -0.691535  ,  0.927494  ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 8, 768), dtype=float32, numpy=\n",
       " array([[[-0.05949632,  0.00605975, -0.2815995 , ..., -0.4041223 ,\n",
       "           0.1339953 ,  0.62050724],\n",
       "         [-0.49181765, -0.44987425, -0.2768544 , ..., -0.56022567,\n",
       "           0.48811057,  0.54658276],\n",
       "         [-0.15118755, -0.48845524,  0.24918537, ..., -0.14918858,\n",
       "           0.21074021,  0.97774243],\n",
       "         ...,\n",
       "         [ 0.14526199, -0.12205253, -0.0597409 , ..., -0.11260532,\n",
       "          -0.15715161, -0.34151724],\n",
       "         [ 0.60058045,  0.10146077, -0.71891844, ...,  0.1999948 ,\n",
       "          -0.6291844 , -0.45430312],\n",
       "         [-0.16071038, -0.09232669, -0.06099205, ..., -0.00320832,\n",
       "          -0.3935948 ,  0.6855434 ]]], dtype=float32)>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dcnn.bert_layer([tf.expand_dims(tf.cast(get_ids(test_sentence), tf.int32), 0),\n",
    "                 tf.expand_dims(tf.cast(get_mask(test_sentence), tf.int32), 0),\n",
    "                 tf.expand_dims(tf.cast(get_segments(test_sentence), tf.int32), 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JpHDseF0QLl3"
   },
   "outputs": [],
   "source": [
    "if NB_CLASSES == 2:\n",
    "    Dcnn.compile(loss=\"binary_crossentropy\",\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=[\"accuracy\"])\n",
    "else:\n",
    "    Dcnn.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=[\"sparse_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "K1hdT_JT2Rfi",
    "outputId": "1dea9a59-b1dd-43e4-b50a-00122225ee28"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./ckpt/\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print(\"Latest checkpoint restored!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e8LHztku2cjl"
   },
   "outputs": [],
   "source": [
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        ckpt_manager.save()\n",
    "        print(\"Checkpoint saved at {}.\".format(checkpoint_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V0C5lNxFTMrA"
   },
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "WrT8oWZzQNmW",
    "outputId": "3f196a33-cbe1-4e71-e2ef-59fe1ea0d4dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   5078/Unknown - 987s 194ms/step - loss: 0.3957 - accuracy: 0.8213Checkpoint saved at ./ckpt/.\n",
      "5078/5078 [==============================] - 988s 195ms/step - loss: 0.3957 - accuracy: 0.8213\n",
      "Epoch 2/5\n",
      "5077/5078 [============================>.] - ETA: 0s - loss: 0.3661 - accuracy: 0.8372Checkpoint saved at ./ckpt/.\n",
      "5078/5078 [==============================] - 977s 192ms/step - loss: 0.3662 - accuracy: 0.8372\n",
      "Epoch 3/5\n",
      "5077/5078 [============================>.] - ETA: 0s - loss: 0.3510 - accuracy: 0.8449Checkpoint saved at ./ckpt/.\n",
      "5078/5078 [==============================] - 977s 192ms/step - loss: 0.3510 - accuracy: 0.8449\n",
      "Epoch 4/5\n",
      "5077/5078 [============================>.] - ETA: 0s - loss: 0.3384 - accuracy: 0.8508Checkpoint saved at ./ckpt/.\n",
      "5078/5078 [==============================] - 979s 193ms/step - loss: 0.3384 - accuracy: 0.8507\n",
      "Epoch 5/5\n",
      "5077/5078 [============================>.] - ETA: 0s - loss: 0.3270 - accuracy: 0.8558Checkpoint saved at ./ckpt/.\n",
      "5078/5078 [==============================] - 979s 193ms/step - loss: 0.3271 - accuracy: 0.8558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f11dad912e8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dcnn.fit(train_dataset,\n",
    "         epochs=NB_EPOCHS,\n",
    "         callbacks=[MyCustomCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dcnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_1 (KerasLayer)   multiple                  109482241 \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              multiple                  153700    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            multiple                  230500    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            multiple                  307300    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  77056     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  257       \n",
      "=================================================================\n",
      "Total params: 110,251,054\n",
      "Trainable params: 768,813\n",
      "Non-trainable params: 109,482,241\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Dcnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MAb_ijA5Idmz"
   },
   "source": [
    "# Stage 5: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "gQN-Y99WIf6m",
    "outputId": "8ff576c9-59ea-49fb-f186-279fa8c8e299"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    564/Unknown - 46s 82ms/step - loss: 0.3412 - accuracy: 0.8526[0.34118841488099266, 0.85255986]\n"
     ]
    }
   ],
   "source": [
    "results = Dcnn.evaluate(test_dataset)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rj98dgxnmhak"
   },
   "outputs": [],
   "source": [
    "def get_prediction(sentence):\n",
    "    tokens = encode_sentence(sentence)\n",
    "\n",
    "    input_ids = get_ids(tokens)\n",
    "    input_mask = get_mask(tokens)\n",
    "    segment_ids = get_segments(tokens)\n",
    "\n",
    "    inputs = tf.stack(\n",
    "        [tf.cast(input_ids, dtype=tf.int32),\n",
    "         tf.cast(input_mask, dtype=tf.int32),\n",
    "         tf.cast(segment_ids, dtype=tf.int32)],\n",
    "         axis=0)\n",
    "    inputs = tf.expand_dims(inputs, 0) # simulates a batch\n",
    "\n",
    "    output = Dcnn(inputs, training=False)\n",
    "\n",
    "    sentiment = math.floor(output*2)\n",
    "\n",
    "    if sentiment == 0:\n",
    "        print(\"Output of the model: {}\\nPredicted sentiment: negative\".format(\n",
    "            output))\n",
    "    elif sentiment == 1:\n",
    "        print(\"Output of the model: {}\\nPredicted sentiment: positive\".format(\n",
    "            output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "J9jC8UnJgOjS",
    "outputId": "808b061b-e80e-4f3c-ecda-3dba81606e1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: He is a good teacher!\n",
      "Output of the model: [[0.95472294]]\n",
      "Predicted sentiment: positive\n",
      "Input sentence: This actor is a deception.\n",
      "Output of the model: [[0.17139843]]\n",
      "Predicted sentiment: negative\n",
      "Input sentence: It's an awesome movie!\n",
      "Output of the model: [[0.95668626]]\n",
      "Predicted sentiment: positive\n",
      "Input sentence: it's the worst movie I've ever seen\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function recreate_function.<locals>.restored_function_body at 0x7f11dbb1ed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function recreate_function.<locals>.restored_function_body at 0x7f11dbb1ed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the model: [[0.00916532]]\n",
      "Predicted sentiment: negative\n",
      "Input sentence: that's bullshit\n",
      "WARNING:tensorflow:6 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x7f11dbb1ed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x7f11dbb1ed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the model: [[0.0866849]]\n",
      "Predicted sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\"He is a good teacher!\",\n",
    "                  \"This actor is a deception.\",\n",
    "                  \"It's an awesome movie!\",\n",
    "                  \"it's the worst movie I've ever seen\",\n",
    "                  \"that's bullshit\"]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    print(\"Input sentence: {}\".format(sentence))\n",
    "    get_prediction(sentence)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT_embedding",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
